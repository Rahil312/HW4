## PARALLEL SYSTEMS HW1
## README for MPI Latency Analysis

## Overview
This experiment measures point-to-point message latency using MPI across four communication scenarios with varying numbers of node pairs. Message sizes range from 32 KB to 2 MB. The average round-trip time (RTT) is computed over 10 iterations for each scenario and message size, with the results visualized in the provided graph. This README discusses the observed trends, compares scenarios, and evaluates the relationship between message sizes and latency.

---

## Experimental Scenarios
1. **Scenario 1**: Communication between one pair of nodes.
2. **Scenario 2**: Communication between two pairs of nodes in parallel.
3. **Scenario 3**: Communication between three pairs of nodes in parallel.
4. **Scenario 4**: Communication between four pairs of nodes in parallel.

Message sizes tested: **32 KB, 64 KB, 128 KB, 256 KB, 512 KB, 1 MB, and 2 MB**.

---

## Observations and Trends

### 1. Comparison Across Scenarios
- **Scenario 1 (1 Pair of Nodes)**:
  - Demonstrates the highest average RTT for larger message sizes (e.g., 2 MB) compared to other scenarios.
  - Smaller message sizes (32 KB and 64 KB) show high variability, with an outlier at 168 ms for 32 KB messages, likely due to initialization overhead or external network interference.
  
- **Scenario 2 (2 Pairs of Nodes)**:
  - Shows a moderate increase in RTT as the message size grows. For smaller message sizes, RTT is lower and more stable compared to Scenario 1.
  - For larger messages (1 MB and 2 MB), latency increases significantly, indicating the impact of network contention with more communication pairs.

- **Scenario 3 (3 Pairs of Nodes)**:
  - Exhibits higher RTT for larger message sizes (e.g., 1 MB and 2 MB) compared to Scenarios 1 and 2, reflecting increased network load.
  - Variability increases for messages larger than 256 KB, as observed in the higher standard deviation in the plot.

- **Scenario 4 (4 Pairs of Nodes)**:
  - Displays the highest overall latency, particularly for the largest message size (2 MB), where RTT exceeds 1200 ms on average.
  - Network saturation becomes evident, as increasing the number of communication pairs introduces significant contention.

---

### 2. Message Size and Latency
- **General Trend**:
  - Latency consistently increases with message size across all scenarios. Larger messages require more time to transmit due to the increased data volume and the limits of network bandwidth.
  
- **Unusual Data Points**:
  - An outlier in **Scenario 1** for the 32 KB message size (168 ms RTT) suggests initialization overhead or an external network disturbance.
  - In **Scenario 2**, RTT for 128 KB and 256 KB messages is slightly higher compared to adjacent sizes, indicating temporary network contention or inefficiencies in data handling.
  - Variability in Scenarios 3 and 4 is more pronounced for messages larger than 512 KB, likely due to the compounded effect of multiple communication pairs.

---

## Network Configuration Insights
1. **Scalability**:
   - The network demonstrates good scalability for smaller message sizes (32 KB to 256 KB) even as the number of communication pairs increases.
   - For larger message sizes (1 MB and 2 MB), scalability diminishes significantly due to increased contention and saturation of available bandwidth.

2. **Latency Variability**:
   - Larger message sizes (e.g., 1 MB and 2 MB) exhibit higher standard deviation in RTT, particularly in Scenarios 3 and 4. This reflects the sensitivity of the network to higher loads and contention under these conditions.

3. **Bottlenecks**:
   - The results suggest that network bandwidth becomes a bottleneck as both the number of communication pairs and message sizes increase. Optimizing the network configuration or introducing more bandwidth could mitigate these delays.

---

## Key Takeaways
1. **Network Performance**:
   - Smaller message sizes show lower and more consistent RTTs, making them ideal for parallel communication in distributed systems.
   - Larger message sizes introduce significant latency, especially with an increasing number of communication pairs.

2. **Optimization Suggestions**:
   - Batching smaller messages, reducing network contention through scheduling, or using a high-speed network could improve overall latency.
   - Analyzing the root cause of outliers and variability could identify opportunities for optimization.

3. **Future Improvements**:
   - Testing under a dedicated network or employing a higher precision timing mechanism may yield more reliable results.
   - Investigating load balancing and contention management strategies could improve scalability for large-scale applications.

---

## Conclusion
The experiment successfully measured and analyzed MPI latency across different scenarios and message sizes. The results demonstrate the impact of message size, communication pairs, and network configuration on performance, providing valuable insights for optimizing MPI-based distributed applications.
